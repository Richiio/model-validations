{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "DATAPATH = \"../data\"\n",
    "SMICOL = \"smiles\"\n",
    "INCHICOL = \"inchikey\"\n",
    "ACTCOL = \"activity\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Model Training datasets\n",
    "\n",
    "First, we clean up the original files and add the InChiKey of the smiles if not available. We want to create a dataframe with three columns, smiles, inchikey and activity. We will store each dataset under data/model_datasets/{model_name}_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:44:13] non-ring atom 10 marked aromatic\n",
      "[17:44:13] non-ring atom 12 marked aromatic\n",
      "[17:44:13] non-ring atom 10 marked aromatic\n",
      "[17:44:13] non-ring atom 14 marked aromatic\n",
      "[17:44:13] non-ring atom 10 marked aromatic\n",
      "[17:44:13] non-ring atom 10 marked aromatic\n",
      "[17:44:13] non-ring atom 10 marked aromatic\n",
      "[17:44:14] non-ring atom 21 marked aromatic\n",
      "[17:44:14] non-ring atom 10 marked aromatic\n",
      "[17:44:14] non-ring atom 10 marked aromatic\n",
      "[17:44:14] non-ring atom 12 marked aromatic\n",
      "[17:44:14] non-ring atom 12 marked aromatic\n",
      "[17:44:15] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:15] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:16] Explicit valence for atom # 0 N, 4, is greater than permitted\n",
      "[17:44:17] Explicit valence for atom # 0 N, 5, is greater than permitted\n",
      "[17:44:17] Explicit valence for atom # 0 N, 5, is greater than permitted\n",
      "[17:44:17] Explicit valence for atom # 0 N, 5, is greater than permitted\n",
      "[17:44:17] Explicit valence for atom # 0 N, 5, is greater than permitted\n",
      "[17:44:17] Explicit valence for atom # 0 N, 5, is greater than permitted\n",
      "[17:44:17] Explicit valence for atom # 0 N, 5, is greater than permitted\n",
      "[17:44:18] non-ring atom 11 marked aromatic\n",
      "[17:44:18] non-ring atom 13 marked aromatic\n",
      "[17:44:18] non-ring atom 10 marked aromatic\n",
      "[17:44:18] non-ring atom 10 marked aromatic\n",
      "[17:44:18] non-ring atom 11 marked aromatic\n",
      "[17:44:18] non-ring atom 10 marked aromatic\n",
      "[17:44:18] non-ring atom 10 marked aromatic\n",
      "[17:44:18] non-ring atom 9 marked aromatic\n",
      "[17:44:18] non-ring atom 21 marked aromatic\n",
      "[17:44:18] non-ring atom 10 marked aromatic\n",
      "[17:44:18] non-ring atom 10 marked aromatic\n",
      "[17:44:18] non-ring atom 13 marked aromatic\n",
      "[17:44:18] non-ring atom 10 marked aromatic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smiles eliminated:  49\n"
     ]
    }
   ],
   "source": [
    "#eos30gr\n",
    "\n",
    "train_data = pd.read_excel(os.path.join(DATAPATH, \"model_datasets\", \"eos30gr.xlsx\"), sheet_name=0)\n",
    "test_data = pd.read_excel(os.path.join(DATAPATH, \"model_datasets\", \"eos30gr.xlsx\"), sheet_name=1)\n",
    "valid_data = pd.read_excel(os.path.join(DATAPATH, \"model_datasets\", \"eos30gr.xlsx\"), sheet_name=2)\n",
    "eos30gr = pd.concat([train_data, test_data, valid_data])\n",
    "\n",
    "inchikeys = []\n",
    "for smi in eos30gr[\"Smiles\"]:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        inchikey = Chem.MolToInchiKey(mol)\n",
    "    else:\n",
    "        inchikey = None\n",
    "    inchikeys += [inchikey]\n",
    "\n",
    "eos30gr[INCHICOL] = inchikeys\n",
    "total_len = len(eos30gr)\n",
    "eos30gr.dropna(subset=[INCHICOL], inplace=True)\n",
    "print(\"Smiles eliminated: \", total_len-len(eos30gr))\n",
    "eos30gr.rename(columns={\"Smiles\":SMICOL, \"activity10\":ACTCOL}, inplace=True) #looking at the model, activity 10 was chosen for activity\n",
    "eos30gr = eos30gr[[SMICOL, INCHICOL, ACTCOL]]\n",
    "eos30gr.to_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos30gr_processed.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1544968/3774300218.py:3: DtypeWarning: Columns (118,119,120,124,125,126,130,131,132,136,137,138,142,143,144,148,149,150,154,155,156,160,161,162,166,167,168,172,173,174,268,269,270,274,275,276,280,281,282,286,287,288,292,293,294,298,299,300,304,305,306,310,311,312,316,317,318,322,323,324,327,328,329,332,333,334,337,338,339,342,343,344,347,348,349,352,353,354,357,358,359,362,363,364,367,368,369,372,373,374,377,378,379,382,383,384,387,388,389,392,393,394,397,398,399,402,403,404,407,408,409,412,413,414,417,418,419,422,423,424,480,481,482,483,493,494,495,496,720) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos2ta5\", \"train_validation_cardio_tox_data.csv\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smiles eliminated:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1544968/3774300218.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  eos2ta5[INCHICOL] = inchikeys\n"
     ]
    }
   ],
   "source": [
    "#eos2ta5\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos2ta5\", \"train_validation_cardio_tox_data.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos2ta5\", 'external_test_set_neg.csv'))\n",
    "test_data2 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos2ta5\", 'external_test_set_new.csv'))\n",
    "test_data3 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos2ta5\", 'external_test_set_pos.csv'))\n",
    "valid_data = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos2ta5\", \"valid_cardio_tox_data.csv\"))\n",
    "valid_data2 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos2ta5\", \"validation_cardio_tox_data.csv\"))\n",
    "eos2ta5 = pd.concat([train_data, test_data,test_data2, test_data3, valid_data, valid_data2])\n",
    "\n",
    "inchikeys = []\n",
    "for smi in eos2ta5[\"smiles\"]:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        inchikey = Chem.MolToInchiKey(mol)\n",
    "    else:\n",
    "        inchikey = None\n",
    "    inchikeys += [inchikey]\n",
    "\n",
    "eos2ta5[INCHICOL] = inchikeys\n",
    "total_len = len(eos2ta5)\n",
    "eos2ta5.dropna(subset=[INCHICOL], inplace=True)\n",
    "print(\"Smiles eliminated: \", total_len-len(eos2ta5))\n",
    "eos2ta5.rename(columns={\"smiles\":SMICOL, \"ACTIVITY\":ACTCOL}, inplace=True) #looking at the model, activity 10 was chosen for activity\n",
    "eos2ta5 = eos2ta5[[SMICOL, INCHICOL, ACTCOL]]\n",
    "eos2ta5.to_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos2ta5_processed.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:50:40] WARNING: not removing hydrogen atom without neighbors\n",
      "[17:50:40] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smiles eliminated:  0\n"
     ]
    }
   ],
   "source": [
    "#eos4tcc\n",
    "train_data = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos4tcc\",\"pretraining_eos4tcc\", \"MLSMR_training.csv\"))\n",
    "train_data2 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos4tcc\", \"pretraining_eos4tcc\", \"MLSMR_validation.csv\"))\n",
    "finetuning_data = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos4tcc\", \"finetuning_eos4tcc\", \"test_all.csv\"))\n",
    "finetuning_data2 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos4tcc\", \"finetuning_eos4tcc\", \"test_rev.csv\"))\n",
    "finetuning_data3 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos4tcc\", \"finetuning_eos4tcc\", \"training.csv\"))\n",
    "finetuning_data4 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos4tcc\", \"finetuning_eos4tcc\", \"val_all.csv\"))\n",
    "finetuning_data5 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos4tcc\", \"finetuning_eos4tcc\", \"val_rev.csv\"))\n",
    "external_data = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos4tcc\", \"external_eos4tcc\", \"EX1.csv\"))\n",
    "external_data2 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos4tcc\", \"external_eos4tcc\", \"EX2.csv\"))\n",
    "external_data3 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos4tcc\", \"external_eos4tcc\", \"EX3.csv\"))\n",
    "external_data4 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos4tcc\", \"external_eos4tcc\", \"EX4.csv\"))\n",
    "eos4tcc = pd.concat([train_data,train_data2, finetuning_data, finetuning_data2,finetuning_data3,finetuning_data4,finetuning_data5,external_data, external_data2,external_data3,external_data4 ])\n",
    "\n",
    "inchikeys = []\n",
    "for smi in eos4tcc[\"smiles\"]:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        inchikey = Chem.MolToInchiKey(mol)\n",
    "    else:\n",
    "        inchikey = None\n",
    "    inchikeys += [inchikey]\n",
    "\n",
    "eos4tcc[INCHICOL] = inchikeys\n",
    "total_len = len(eos4tcc)\n",
    "eos4tcc.dropna(subset=[INCHICOL], inplace=True)\n",
    "print(\"Smiles eliminated: \", total_len-len(eos4tcc))\n",
    "eos4tcc.rename(columns={\"smiles\":SMICOL, \"label\":ACTCOL}, inplace=True) \n",
    "eos4tcc = eos4tcc[[SMICOL, INCHICOL, ACTCOL]]\n",
    "eos4tcc.to_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos4tcc_processed.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smiles eliminated:  0\n"
     ]
    }
   ],
   "source": [
    "# Reading Data with .read_csv for CSV file\n",
    "train_data = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos30f3\", \"Cai_TableS3_fixed.csv\"))\n",
    "\n",
    "# Concatenating Data\n",
    "eos30f3 = pd.concat([train_data])\n",
    "\n",
    "# Generating InChiKeys\n",
    "inchikeys = []\n",
    "for smi in eos30f3[\"smiles\"]:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        inchikey = Chem.MolToInchiKey(mol)\n",
    "    else:\n",
    "        inchikey = None\n",
    "    inchikeys += [inchikey]\n",
    "\n",
    "# Adding InChiKeys to DataFrame and Dropping NaN Values\n",
    "eos30f3[INCHICOL] = inchikeys\n",
    "total_len = len(eos30f3)\n",
    "eos30f3.dropna(subset=[INCHICOL], inplace=True)\n",
    "print(\"Smiles eliminated: \", total_len - len(eos30f3))\n",
    "\n",
    "# Renaming Columns\n",
    "eos30f3.rename(columns={\"smiles\": SMICOL, \"X10\": ACTCOL}, inplace=True)\n",
    "\n",
    "# Selecting Columns\n",
    "eos30f3 = eos30f3[[SMICOL, INCHICOL, ACTCOL]]\n",
    "\n",
    "# Saving Processed Data\n",
    "eos30f3.to_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos30f3_processed.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smiles eliminated:  0\n"
     ]
    }
   ],
   "source": [
    "#eos43at\n",
    "## The training files has no activity column\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos43at\",\"CHEMBL1909307.csv\"))\n",
    "train_data2 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos43at\", 'CHEMBL1909308.csv'))\n",
    "train_data3 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos43at\", 'CHEMBL1909313.csv'))\n",
    "train_data4 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos43at\", 'CHEMBL1909314.csv'))\n",
    "train_data5 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos43at\", \"CHEMBL1909317.csv\"))\n",
    "train_data6 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos43at\", \"CHEMBL3039488.csv\"))\n",
    "train_data7 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos43at\", 'CHEMBL3039491.csv'))\n",
    "train_data8 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos43at\", 'CHEMBL3301364.csv'))\n",
    "train_data9 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos43at\", 'CHEMBL3301365.csv'))\n",
    "train_data10 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos43at\", \"CHEMBL3301366.csv\"))\n",
    "train_data11 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos43at\", \"CHEMBL3301370.csv\"))\n",
    "train_data12 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\",\"eos43at\", \"CHEMBL3301371.csv\"))\n",
    "train_data13 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos43at\", 'CHEMBL3301372.csv'))\n",
    "train_data14 = pd.read_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos43at\", 'CHEMBL4029349.csv'))\n",
    "eos43at = pd.concat([train_data, train_data2,train_data3, train_data4, train_data5, train_data6, train_data7, train_data8, train_data9, train_data10, train_data11,train_data12, train_data13, train_data14])\n",
    "\n",
    "# Convert InChI to SMILES\n",
    "inchi_to_smiles = {}\n",
    "for inchi in eos43at['inchi']:\n",
    "    if inchi is not None:\n",
    "        mol = Chem.MolFromInchi(inchi)\n",
    "        if mol is not None:\n",
    "            smiles = Chem.MolToSmiles(mol)\n",
    "            inchi_to_smiles[inchi] = smiles\n",
    "\n",
    "# Add a new column with SMILES to eos43at DataFrame\n",
    "eos43at['Smiles'] = eos43at['inchi'].map(inchi_to_smiles)\n",
    "\n",
    "# Drop rows with missing values in the InChI column\n",
    "total_len = len(eos43at)\n",
    "eos43at.dropna(subset=['inchi'], inplace=True)\n",
    "print(\"Smiles eliminated: \", total_len - len(eos43at))\n",
    "\n",
    "# Rename columns and select desired columns\n",
    "eos43at.rename(columns={\"Smiles\": SMICOL,'inchi': INCHICOL}, inplace=True)\n",
    "eos43at = eos43at[[SMICOL, INCHICOL]]\n",
    "\n",
    "# Save processed data to a new CSV file\n",
    "eos43at.to_csv(os.path.join(DATAPATH, \"model_datasets\", \"eos43at_processed.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the datasets have been cleaned, we can compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"eos2ta5\", \"eos4tcc\", \"eos30f3\", \"eos30gr\", \"eos43at\"]\n",
    "\n",
    "# load the datasets and make comparisons\n",
    "\n",
    "# proportion of actives and inactives in each dataset\n",
    "\n",
    "# number of repeated smiles between models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build test dataset\n",
    "\n",
    "We collate in a single file the data from the NCATS repository and eliminate any duplicate molecules that exist in the training sets of the models already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(os.path.join(DATAPATH, \"test_data\", \"training_set_ncats.csv\"))\n",
    "df2 = pd.read_csv(os.path.join(DATAPATH, \"test_data\", \"validation_set_ncats.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['smiles', 'activity', 'source'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smiles eliminated:  0\n",
      "Smiles eliminated:  32\n"
     ]
    }
   ],
   "source": [
    "#merge and remove duplicates. Obtain InChiKeys for all\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "inchikeys = []\n",
    "for smi in df[\"smiles\"]:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        inchikey = Chem.MolToInchiKey(mol)\n",
    "    else:\n",
    "        inchikey = None\n",
    "    inchikeys += [inchikey]\n",
    "\n",
    "df[INCHICOL] = inchikeys\n",
    "total_len = len(df)\n",
    "df.dropna(subset=[INCHICOL], inplace=True)\n",
    "print(\"Smiles eliminated: \", total_len-len(df))\n",
    "total_len = len(df)\n",
    "df.drop_duplicates(subset=[SMICOL], inplace=True)\n",
    "print(\"Smiles eliminated: \", total_len-len(df))\n",
    "df = df[[SMICOL, INCHICOL, ACTCOL]]\n",
    "df.to_csv(os.path.join(DATAPATH, \"test_data\", \"ncats.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, from the all NCATS data, we eliminate duplicated molecules with training set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
